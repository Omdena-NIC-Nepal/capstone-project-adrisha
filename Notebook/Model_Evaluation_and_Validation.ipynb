{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33cc651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f98a0f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de242c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data types (Regression):\n",
      " gsid                        int64\n",
      "station_id                  int64\n",
      "year                        int64\n",
      "month                       int64\n",
      "days                        int64\n",
      "unnamed:_8                float64\n",
      "unnamed:_9_x              float64\n",
      "unnamed:_10               float64\n",
      "s_n_                      float64\n",
      "lat(deg)                  float64\n",
      "lon(deg)                  float64\n",
      "ele(meter)                float64\n",
      "yearly_rainfall           float64\n",
      "monthly_rainfall          float64\n",
      "prev_day_rainfall         float64\n",
      "rolling_mean_7d           float64\n",
      "day_of_year               float64\n",
      "log_rainfall_sum          float64\n",
      "log_monthly_rainfall      float64\n",
      "log_prev_day_rainfall     float64\n",
      "log_rolling_mean_7d       float64\n",
      "station_name_x_encoded      int64\n",
      "pca_component_1           float64\n",
      "pca_component_2           float64\n",
      "pca_component_3           float64\n",
      "dtype: object\n",
      "Validation data types (Regression):\n",
      " gsid                        int64\n",
      "station_id                  int64\n",
      "year                        int64\n",
      "month                       int64\n",
      "days                        int64\n",
      "unnamed:_8                float64\n",
      "unnamed:_9_x              float64\n",
      "unnamed:_10               float64\n",
      "s_n_                      float64\n",
      "lat(deg)                  float64\n",
      "lon(deg)                  float64\n",
      "ele(meter)                float64\n",
      "yearly_rainfall           float64\n",
      "monthly_rainfall          float64\n",
      "prev_day_rainfall         float64\n",
      "rolling_mean_7d           float64\n",
      "day_of_year               float64\n",
      "log_rainfall_sum          float64\n",
      "log_monthly_rainfall      float64\n",
      "log_prev_day_rainfall     float64\n",
      "log_rolling_mean_7d       float64\n",
      "station_name_x_encoded      int64\n",
      "pca_component_1           float64\n",
      "pca_component_2           float64\n",
      "pca_component_3           float64\n",
      "dtype: object\n",
      "Training data types (Classification):\n",
      " gsid                        int64\n",
      "station_id                  int64\n",
      "year                        int64\n",
      "month                       int64\n",
      "days                        int64\n",
      "unnamed:_8                float64\n",
      "unnamed:_9_x              float64\n",
      "unnamed:_10               float64\n",
      "s_n_                      float64\n",
      "lat(deg)                  float64\n",
      "lon(deg)                  float64\n",
      "ele(meter)                float64\n",
      "yearly_rainfall           float64\n",
      "monthly_rainfall          float64\n",
      "prev_day_rainfall         float64\n",
      "rolling_mean_7d           float64\n",
      "day_of_year               float64\n",
      "log_rainfall_sum          float64\n",
      "log_monthly_rainfall      float64\n",
      "log_prev_day_rainfall     float64\n",
      "log_rolling_mean_7d       float64\n",
      "station_name_x_encoded      int64\n",
      "pca_component_1           float64\n",
      "pca_component_2           float64\n",
      "pca_component_3           float64\n",
      "dtype: object\n",
      "Validation data types (Classification):\n",
      " gsid                        int64\n",
      "station_id                  int64\n",
      "year                        int64\n",
      "month                       int64\n",
      "days                        int64\n",
      "unnamed:_8                float64\n",
      "unnamed:_9_x              float64\n",
      "unnamed:_10               float64\n",
      "s_n_                      float64\n",
      "lat(deg)                  float64\n",
      "lon(deg)                  float64\n",
      "ele(meter)                float64\n",
      "yearly_rainfall           float64\n",
      "monthly_rainfall          float64\n",
      "prev_day_rainfall         float64\n",
      "rolling_mean_7d           float64\n",
      "day_of_year               float64\n",
      "log_rainfall_sum          float64\n",
      "log_monthly_rainfall      float64\n",
      "log_prev_day_rainfall     float64\n",
      "log_rolling_mean_7d       float64\n",
      "station_name_x_encoded      int64\n",
      "pca_component_1           float64\n",
      "pca_component_2           float64\n",
      "pca_component_3           float64\n",
      "dtype: object\n",
      "Missing values in regression validation data: gsid                          0\n",
      "station_id                    0\n",
      "year                          0\n",
      "month                         0\n",
      "days                          0\n",
      "unnamed:_8                43100\n",
      "unnamed:_9_x              43100\n",
      "unnamed:_10               43100\n",
      "s_n_                          0\n",
      "lat(deg)                      0\n",
      "lon(deg)                      0\n",
      "ele(meter)                    0\n",
      "yearly_rainfall               0\n",
      "monthly_rainfall              0\n",
      "prev_day_rainfall             0\n",
      "rolling_mean_7d               0\n",
      "day_of_year                   0\n",
      "log_rainfall_sum              0\n",
      "log_monthly_rainfall          0\n",
      "log_prev_day_rainfall         0\n",
      "log_rolling_mean_7d           0\n",
      "station_name_x_encoded        0\n",
      "pca_component_1               0\n",
      "pca_component_2               0\n",
      "pca_component_3               0\n",
      "dtype: int64\n",
      "Missing values in classification validation data: gsid                          0\n",
      "station_id                    0\n",
      "year                          0\n",
      "month                         0\n",
      "days                          0\n",
      "unnamed:_8                43100\n",
      "unnamed:_9_x              43100\n",
      "unnamed:_10               43100\n",
      "s_n_                          0\n",
      "lat(deg)                      0\n",
      "lon(deg)                      0\n",
      "ele(meter)                    0\n",
      "yearly_rainfall               0\n",
      "monthly_rainfall              0\n",
      "prev_day_rainfall             0\n",
      "rolling_mean_7d               0\n",
      "day_of_year                   0\n",
      "log_rainfall_sum              0\n",
      "log_monthly_rainfall          0\n",
      "log_prev_day_rainfall         0\n",
      "log_rolling_mean_7d           0\n",
      "station_name_x_encoded        0\n",
      "pca_component_1               0\n",
      "pca_component_2               0\n",
      "pca_component_3               0\n",
      "dtype: int64\n",
      "Error: Feature mismatch. Expected: ['ele(meter)', 'lat(deg)', 'lon(deg)', 'year', 'month', 'day_of_year', 'yearly_rainfall', 'monthly_rainfall', 'prev_day_rainfall', 'rolling_mean_7d', 'station_name_x_encoded', 'log_rainfall_sum', 'log_monthly_rainfall', 'log_prev_day_rainfall', 'log_rolling_mean_7d', 'pca_component_1', 'pca_component_2', 'pca_component_3'], Got: Index(['gsid', 'station_id', 'year', 'month', 'days', 'unnamed:_8',\n",
      "       'unnamed:_9_x', 'unnamed:_10', 's_n_', 'lat(deg)', 'lon(deg)',\n",
      "       'ele(meter)', 'yearly_rainfall', 'monthly_rainfall',\n",
      "       'prev_day_rainfall', 'rolling_mean_7d', 'day_of_year',\n",
      "       'log_rainfall_sum', 'log_monthly_rainfall', 'log_prev_day_rainfall',\n",
      "       'log_rolling_mean_7d', 'station_name_x_encoded', 'pca_component_1',\n",
      "       'pca_component_2', 'pca_component_3'],\n",
      "      dtype='object')\n",
      "Regression Model - Validation Set:\n",
      "MAE: 0.0001\n",
      "RMSE: 0.0024\n",
      "R2: 1.0000\n",
      "Classification Model - Validation Set:\n",
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "ROC-AUC: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation and Validation\n",
    "# Purpose: Evaluate and validate machine learning models for predicting rainfall_sum and extreme_rainfall in Eastern Nepal.\n",
    "\n",
    "\n",
    "# Set output directory\n",
    "OUTPUT_DIR = '../Data/Preprocessed'\n",
    "MODEL_DIR = '../Outputs'\n",
    "\n",
    "# Step 1: Load feature-engineered data\n",
    "data_path = os.path.join(OUTPUT_DIR, 'feature_engineered_data.csv')\n",
    "try:\n",
    "    data = pd.read_csv(data_path, low_memory=False)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {data_path} does not exist. Please ensure the file is in the correct directory.\")\n",
    "    exit()\n",
    "\n",
    "# Step 2: Split data into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Step 3: Prepare features and targets\n",
    "# Define columns to exclude (non-numeric or irrelevant)\n",
    "exclude_columns = [\n",
    "    'rainfall_sum', 'extreme_rainfall', 'station_name_x', 'district_x', 'station_name_y',\n",
    "    'basin_office', 'types_of_station', 'district_y', 'unnamed:_9_y', 'date'\n",
    "]\n",
    "\n",
    "# Select only numeric columns and exclude target columns\n",
    "numeric_columns = data.select_dtypes(include=[np.number]).columns\n",
    "feature_columns = [col for col in numeric_columns if col not in exclude_columns]\n",
    "\n",
    "# Prepare training and validation data\n",
    "try:\n",
    "    X_train_reg = train_data[feature_columns]\n",
    "    y_train_reg = train_data['rainfall_sum']\n",
    "    X_val_reg = val_data[feature_columns]\n",
    "    y_val_reg = val_data['rainfall_sum']\n",
    "\n",
    "    X_train_clf = train_data[feature_columns]\n",
    "    y_train_clf = train_data['extreme_rainfall']\n",
    "    X_val_clf = val_data[feature_columns]\n",
    "    y_val_clf = val_data['extreme_rainfall']\n",
    "except KeyError as e:\n",
    "    print(f\"Error: Column not found - {e}. Please check the column names in the dataset.\")\n",
    "    exit()\n",
    "\n",
    "# Debug: Print data types to ensure all are numeric\n",
    "print(\"Training data types (Regression):\\n\", X_train_reg.dtypes)\n",
    "print(\"Validation data types (Regression):\\n\", X_val_reg.dtypes)\n",
    "print(\"Training data types (Classification):\\n\", X_train_clf.dtypes)\n",
    "print(\"Validation data types (Classification):\\n\", X_val_clf.dtypes)\n",
    "\n",
    "# Check for non-numeric columns\n",
    "non_numeric_reg = X_val_reg.select_dtypes(exclude=[np.number]).columns\n",
    "if non_numeric_reg.size > 0:\n",
    "    print(f\"Error: Non-numeric columns in regression validation data: {non_numeric_reg}\")\n",
    "    exit()\n",
    "\n",
    "non_numeric_clf = X_val_clf.select_dtypes(exclude=[np.number]).columns\n",
    "if non_numeric_clf.size > 0:\n",
    "    print(f\"Error: Non-numeric columns in classification validation data: {non_numeric_clf}\")\n",
    "    exit()\n",
    "\n",
    "# Check for missing values\n",
    "if X_val_reg.isnull().sum().sum() > 0:\n",
    "    print(\"Missing values in regression validation data:\", X_val_reg.isnull().sum())\n",
    "    X_val_reg = X_val_reg.fillna(X_val_reg.mean())\n",
    "\n",
    "if X_val_clf.isnull().sum().sum() > 0:\n",
    "    print(\"Missing values in classification validation data:\", X_val_clf.isnull().sum())\n",
    "    X_val_clf = X_val_clf.fillna(X_val_clf.mean())\n",
    "\n",
    "# Step 4: Load trained models\n",
    "best_reg_model_path = os.path.join(MODEL_DIR, 'best_random_forest_regressor_model.pkl')\n",
    "best_clf_model_path = os.path.join(MODEL_DIR, 'best_random_forest_classifier_model.pkl')\n",
    "\n",
    "try:\n",
    "    with open(best_reg_model_path, 'rb') as f:\n",
    "        best_reg_model = pickle.load(f)\n",
    "    with open(best_clf_model_path, 'rb') as f:\n",
    "        best_clf_model = pickle.load(f)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Model file not found - {e}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading models: {e}. Ensure models are compatible with the current scikit-learn version.\")\n",
    "    exit()\n",
    "\n",
    "# Verify feature consistency with trained model\n",
    "if hasattr(best_reg_model, 'feature_names_in_'):\n",
    "    expected_features = list(best_reg_model.feature_names_in_)\n",
    "    if set(X_val_reg.columns) != set(expected_features):\n",
    "        print(f\"Error: Feature mismatch. Expected: {expected_features}, Got: {X_val_reg.columns}\")\n",
    "        exit()\n",
    "    X_val_reg = X_val_reg[expected_features]  # Ensure correct order\n",
    "    X_val_clf = X_val_clf[expected_features]\n",
    "\n",
    "# Step 5: Evaluate models on validation set\n",
    "# Regression evaluation\n",
    "try:\n",
    "    y_pred_reg = best_reg_model.predict(X_val_reg)\n",
    "    mae = mean_absolute_error(y_val_reg, y_pred_reg)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val_reg, y_pred_reg))\n",
    "    r2 = r2_score(y_val_reg, y_pred_reg)\n",
    "    print(\"Regression Model - Validation Set:\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"R2: {r2:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in regression prediction: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Classification evaluation\n",
    "try:\n",
    "    y_pred_clf = best_clf_model.predict(X_val_clf)\n",
    "    accuracy = accuracy_score(y_val_clf, y_pred_clf)\n",
    "    precision = precision_score(y_val_clf, y_pred_clf, zero_division=0)\n",
    "    recall = recall_score(y_val_clf, y_pred_clf, zero_division=0)\n",
    "    f1 = f1_score(y_val_clf, y_pred_clf, zero_division=0)\n",
    "    roc_auc = roc_auc_score(y_val_clf, best_clf_model.predict_proba(X_val_clf)[:, 1])\n",
    "    print(\"Classification Model - Validation Set:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in classification prediction: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Step 6: Cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "try:\n",
    "    cv_r2 = cross_val_score(best_reg_model, X_train_reg, y_train_reg, cv=tscv, scoring='r2')\n",
    "    print(\"Cross-Validation R2 Scores (Regression):\", cv_r2)\n",
    "    print(f\"Mean R2: {cv_r2.mean():.4f}\")\n",
    "    print(f\"Std R2: {cv_r2.std():.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in regression cross-validation: {e}\")\n",
    "\n",
    "try:\n",
    "    cv_f1 = cross_val_score(best_clf_model, X_train_clf, y_train_clf, cv=tscv, scoring='f1')\n",
    "    print(\"Cross-Validation F1 Scores (Classification):\", cv_f1)\n",
    "    print(f\"Mean F1: {cv_f1.mean():.4f}\")\n",
    "    print(f\"Std F1: {cv_f1.std():.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in classification cross-validation: {e}\")\n",
    "\n",
    "# Step 7: Baseline models\n",
    "# Regression baseline (predict mean)\n",
    "mean_pred = np.mean(y_train_reg)\n",
    "baseline_mae = mean_absolute_error(y_val_reg, [mean_pred] * len(y_val_reg))\n",
    "baseline_rmse = np.sqrt(mean_squared_error(y_val_reg, [mean_pred] * len(y_val_reg)))\n",
    "baseline_r2 = r2_score(y_val_reg, [mean_pred] * len(y_val_reg))\n",
    "print(\"Baseline Regression (Mean Prediction):\")\n",
    "print(f\"MAE: {baseline_mae:.4f}\")\n",
    "print(f\"RMSE: {baseline_rmse:.4f}\")\n",
    "print(f\"R2: {baseline_r2:.4f}\")\n",
    "\n",
    "# Classification baseline (majority class)\n",
    "majority_class = y_train_clf.mode()[0]\n",
    "baseline_accuracy = accuracy_score(y_val_clf, [majority_class] * len(y_val_clf))\n",
    "print(\"Baseline Classification (Majority Class):\")\n",
    "print(f\"Accuracy: {baseline_accuracy:.4f}\")\n",
    "\n",
    "# Step 8: Regional evaluation\n",
    "val_data = val_data.copy()  # Avoid SettingWithCopyWarning\n",
    "val_data['pred_rainfall'] = y_pred_reg\n",
    "val_data['pred_extreme'] = y_pred_clf\n",
    "\n",
    "if 'station_id' in val_data.columns:\n",
    "    try:\n",
    "        regional_performance_reg = val_data.groupby('station_id').apply(lambda x: pd.Series({\n",
    "            'MAE': mean_absolute_error(x['rainfall_sum'], x['pred_rainfall']),\n",
    "            'RMSE': np.sqrt(mean_squared_error(x['rainfall_sum'], x['pred_rainfall'])),\n",
    "            'R2': r2_score(x['rainfall_sum'], x['pred_rainfall'])\n",
    "        }))\n",
    "        print(\"Regional Performance - Regression:\")\n",
    "        print(regional_performance_reg)\n",
    "\n",
    "        regional_performance_clf = val_data.groupby('station_id').apply(lambda x: pd.Series({\n",
    "            'Accuracy': accuracy_score(x['extreme_rainfall'], x['pred_extreme']),\n",
    "            'Precision': precision_score(x['extreme_rainfall'], x['pred_extreme'], zero_division=0),\n",
    "            'Recall': recall_score(x['extreme_rainfall'], x['pred_extreme'], zero_division=0),\n",
    "            'F1': f1_score(x['extreme_rainfall'], x['pred_extreme'], zero_division=0)\n",
    "        }))\n",
    "        print(\"Regional Performance - Classification:\")\n",
    "        print(regional_performance_clf)\n",
    "\n",
    "        # Visualize regional R2 for regression\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(x=regional_performance_reg.index, y=regional_performance_reg['R2'])\n",
    "        plt.title('R2 Score by Station (Regression)')\n",
    "        plt.xlabel('Station ID')\n",
    "        plt.ylabel('R2 Score')\n",
    "        plt.savefig(os.path.join(OUTPUT_DIR, 'regional_r2_plot.png'))\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error in regional evaluation: {e}\")\n",
    "else:\n",
    "    print(\"Warning: 'station_id' column not found. Skipping regional evaluation.\")\n",
    "\n",
    "# Step 9: Time period evaluation (by year)\n",
    "if 'date' in val_data.columns:\n",
    "    try:\n",
    "        val_data['year'] = pd.to_datetime(val_data['date'], errors='coerce').dt.year\n",
    "        if val_data['year'].isnull().all():\n",
    "            print(\"Warning: Unable to parse dates. Skipping yearly evaluation.\")\n",
    "        else:\n",
    "            yearly_performance_reg = val_data.groupby('year').apply(lambda x: pd.Series({\n",
    "                'MAE': mean_absolute_error(x['rainfall_sum'], x['pred_rainfall']),\n",
    "                'RMSE': np.sqrt(mean_squared_error(x['rainfall_sum'], x['pred_rainfall'])),\n",
    "                'R2': r2_score(x['rainfall_sum'], x['pred_rainfall'])\n",
    "            }))\n",
    "            print(\"Yearly Performance - Regression:\")\n",
    "            print(yearly_performance_reg)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in yearly evaluation: {e}\")\n",
    "else:\n",
    "    print(\"Warning: 'date' column not found. Skipping yearly evaluation.\")\n",
    "\n",
    "# Step 10: Save evaluation results\n",
    "results = [\n",
    "    {'Model': 'Best Regression Model', 'Metric': 'MAE', 'Value': mae},\n",
    "    {'Model': 'Best Regression Model', 'Metric': 'RMSE', 'Value': rmse},\n",
    "    {'Model': 'Best Regression Model', 'Metric': 'R2', 'Value': r2},\n",
    "    {'Model': 'Best Classification Model', 'Metric': 'Accuracy', 'Value': accuracy},\n",
    "    {'Model': 'Best Classification Model', 'Metric': 'Precision', 'Value': precision},\n",
    "    {'Model': 'Best Classification Model', 'Metric': 'Recall', 'Value': recall},\n",
    "    {'Model': 'Best Classification Model', 'Metric': 'F1', 'Value': f1},\n",
    "    {'Model': 'Best Classification Model', 'Metric': 'ROC-AUC', 'Value': roc_auc},\n",
    "    {'Model': 'Baseline Regression', 'Metric': 'MAE', 'Value': baseline_mae},\n",
    "    {'Model': 'Baseline Regression', 'Metric': 'RMSE', 'Value': baseline_rmse},\n",
    "    {'Model': 'Baseline Regression', 'Metric': 'R2', 'Value': baseline_r2},\n",
    "    {'Model': 'Baseline Classification', 'Metric': 'Accuracy', 'Value': baseline_accuracy}\n",
    "]\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(os.path.join(OUTPUT_DIR, 'model_evaluation_results.csv'), index=False)\n",
    "\n",
    "if 'station_id' in val_data.columns:\n",
    "    regional_performance_reg.to_csv(os.path.join(OUTPUT_DIR, 'regional_performance_regression.csv'))\n",
    "    regional_performance_clf.to_csv(os.path.join(OUTPUT_DIR, 'regional_performance_classification.csv'))\n",
    "if 'date' in val_data.columns and not val_data['year'].isnull().all():\n",
    "    yearly_performance_reg.to_csv(os.path.join(OUTPUT_DIR, 'yearly_performance_regression.csv'))\n",
    "\n",
    "print(\"Evaluation complete. Results saved to CSV files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4b3869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
