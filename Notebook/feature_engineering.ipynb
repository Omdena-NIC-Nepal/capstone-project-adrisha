{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9349be2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5b07d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cf74657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data loaded successfully.\n",
      "\n",
      "--- Creating New Features ---\n",
      "New features created: yearly_rainfall, monthly_rainfall, extreme_rainfall, prev_day_rainfall, rolling_mean_7d, day_of_year\n",
      "\n",
      "--- Transforming Features ---\n",
      "Log-transformed rainfall_sum (skewness: 5.89)\n",
      "Log-transformed monthly_rainfall (skewness: 2.04)\n",
      "Log-transformed prev_day_rainfall (skewness: 5.89)\n",
      "Log-transformed rolling_mean_7d (skewness: 3.34)\n",
      "Standardized numerical features: ['rainfall_sum', 'yearly_rainfall', 'monthly_rainfall', 'prev_day_rainfall', 'rolling_mean_7d', 'ele(meter)', 'lat(deg)', 'lon(deg)', 'day_of_year', 'log_rainfall_sum', 'log_monthly_rainfall', 'log_prev_day_rainfall', 'log_rolling_mean_7d']\n",
      "\n",
      "--- Encoding Categorical Features ---\n",
      "Encoded station_name_x into station_name_x_encoded\n",
      "\n",
      "--- Selecting Best Features ---\n",
      "Selected features: ['gsid', 'yearly_rainfall', 'monthly_rainfall', 'extreme_rainfall', 'prev_day_rainfall', 'rolling_mean_7d', 'log_rainfall_sum', 'log_monthly_rainfall', 'log_prev_day_rainfall', 'log_rolling_mean_7d']\n",
      "\n",
      "Feature scores:\n",
      "                    Feature          Score\n",
      "18        log_rainfall_sum  373865.304480\n",
      "14        extreme_rainfall  310378.255101\n",
      "16         rolling_mean_7d   92367.025133\n",
      "21     log_rolling_mean_7d   63953.252809\n",
      "13        monthly_rainfall   51639.902907\n",
      "20   log_prev_day_rainfall   27665.655830\n",
      "19    log_monthly_rainfall   25875.884908\n",
      "15       prev_day_rainfall   22795.466362\n",
      "12         yearly_rainfall    2948.248756\n",
      "0                     gsid     898.766487\n",
      "1               station_id     801.412432\n",
      "3                    month     746.439434\n",
      "17             day_of_year     732.351067\n",
      "10                lon(deg)     612.687186\n",
      "8                     s_n_     378.345792\n",
      "22  station_name_x_encoded     108.612699\n",
      "9                 lat(deg)     105.670806\n",
      "11              ele(meter)      28.716243\n",
      "2                     year       7.628000\n",
      "4                     days       7.558965\n",
      "7              unnamed:_10       0.003726\n",
      "6             unnamed:_9_x       0.003726\n",
      "5               unnamed:_8       0.003726\n",
      "\n",
      "--- Dimensionality Reduction (PCA) ---\n",
      "PCA explained variance ratios: [9.96295342e-01 2.16969717e-03 4.69128604e-04]\n",
      "Feature-engineered data saved to ../Data/Preprocessed/feature_engineered_data.csv\n",
      "Feature engineering completed successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Feature Engineering for rainfall trend analysis in Eastern Nepal.\n",
    "This script loads preprocessed data, creates new features, transforms features,\n",
    "encodes categorical variables, selects the best features, and optionally applies\n",
    "dimensionality reduction.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Define file paths\n",
    "PREPROCESSED_PATH = '../Data/Preprocessed'\n",
    "OUTPUT_PATH = '../Outputs'\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Load preprocessed training data.\"\"\"\n",
    "    try:\n",
    "        data = pd.read_csv(os.path.join(PREPROCESSED_PATH, 'train_data.csv'))\n",
    "        data['date'] = pd.to_datetime(data['date'])\n",
    "        print(\"Preprocessed data loaded successfully.\")\n",
    "        return data\n",
    "    except FileNotFoundError as e:\n",
    "        raise FileNotFoundError(f\"Error: {e}. Check if train_data.csv exists in {PREPROCESSED_PATH}\")\n",
    "\n",
    "def create_new_features(data):\n",
    "    \"\"\"Create new features for trend analysis.\"\"\"\n",
    "    print(\"\\n--- Creating New Features ---\")\n",
    "    # Yearly total rainfall per station\n",
    "    data['yearly_rainfall'] = data.groupby(['station_name_x', 'year'])['rainfall_sum'].transform('sum')\n",
    "    \n",
    "    # Monthly total rainfall per station\n",
    "    data['monthly_rainfall'] = data.groupby(['station_name_x', 'year', 'month'])['rainfall_sum'].transform('sum')\n",
    "    \n",
    "    # Extreme rainfall indicator (>50 mm daily, typical threshold for heavy rain)\n",
    "    data['extreme_rainfall'] = (data['rainfall_sum'] > 50).astype(int)\n",
    "    \n",
    "    # Previous day's rainfall (lagged feature)\n",
    "    data = data.sort_values(['station_name_x', 'date'])\n",
    "    data['prev_day_rainfall'] = data.groupby('station_name_x')['rainfall_sum'].shift(1)\n",
    "    data['prev_day_rainfall'] = data['prev_day_rainfall'].fillna(0)\n",
    "    \n",
    "    # Rolling mean of rainfall (7-day window)\n",
    "    data['rolling_mean_7d'] = data.groupby('station_name_x')['rainfall_sum'].rolling(window=7, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "    \n",
    "    # Day of year for seasonal patterns\n",
    "    data['day_of_year'] = data['date'].dt.dayofyear\n",
    "    \n",
    "    print(\"New features created: yearly_rainfall, monthly_rainfall, extreme_rainfall, prev_day_rainfall, rolling_mean_7d, day_of_year\")\n",
    "    return data\n",
    "\n",
    "def transform_features(data):\n",
    "    \"\"\"Transform numerical features to handle skewness and scale.\"\"\"\n",
    "    print(\"\\n--- Transforming Features ---\")\n",
    "    numerical_cols = ['rainfall_sum', 'yearly_rainfall', 'monthly_rainfall', 'prev_day_rainfall', 'rolling_mean_7d', 'ele(meter)', 'lat(deg)', 'lon(deg)', 'day_of_year']\n",
    "    \n",
    "    # Log-transform skewed features\n",
    "    for col in numerical_cols:\n",
    "        if col in data.columns:\n",
    "            # Check skewness\n",
    "            skewness = skew(data[col].dropna())\n",
    "            if skewness > 1:  # Highly positively skewed\n",
    "                data[f'log_{col}'] = np.log1p(data[col])\n",
    "                print(f\"Log-transformed {col} (skewness: {skewness:.2f})\")\n",
    "    \n",
    "    # Standardize numerical features\n",
    "    scaler = StandardScaler()\n",
    "    scaled_cols = [col for col in numerical_cols if col in data.columns] + [f'log_{col}' for col in numerical_cols if f'log_{col}' in data.columns]\n",
    "    if scaled_cols:\n",
    "        data[scaled_cols] = scaler.fit_transform(data[scaled_cols])\n",
    "        print(\"Standardized numerical features:\", scaled_cols)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def encode_categorical_features(data):\n",
    "    \"\"\"Encode categorical features.\"\"\"\n",
    "    print(\"\\n--- Encoding Categorical Features ---\")\n",
    "    categorical_cols = ['station_name_x', 'district']\n",
    "    encoders = {}\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        if col in data.columns:\n",
    "            le = LabelEncoder()\n",
    "            data[f'{col}_encoded'] = le.fit_transform(data[col])\n",
    "            encoders[col] = le\n",
    "            print(f\"Encoded {col} into {col}_encoded\")\n",
    "    \n",
    "    # Save encoders for future use\n",
    "    import pickle\n",
    "    with open(os.path.join(OUTPUT_PATH, 'label_encoders.pkl'), 'wb') as f:\n",
    "        pickle.dump(encoders, f)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def select_best_features(data, target='rainfall_sum', k=10):\n",
    "    \"\"\"Select the best features using statistical tests.\"\"\"\n",
    "    print(\"\\n--- Selecting Best Features ---\")\n",
    "    # Features to consider (exclude target and non-numeric columns)\n",
    "    feature_cols = [col for col in data.columns if col not in [target, 'date', 'station_name_x', 'district'] and data[col].dtype in ['int64', 'float64']]\n",
    "    \n",
    "    if not feature_cols:\n",
    "        print(\"No valid features for selection.\")\n",
    "        return data, []\n",
    "    \n",
    "    X = data[feature_cols].fillna(0)\n",
    "    y = data[target].fillna(0)\n",
    "    \n",
    "    # Use SelectKBest with f_regression\n",
    "    selector = SelectKBest(score_func=f_regression, k=min(k, len(feature_cols)))\n",
    "    selector.fit(X, y)\n",
    "    \n",
    "    # Get selected features\n",
    "    selected_features = X.columns[selector.get_support()].tolist()\n",
    "    scores = pd.DataFrame({'Feature': feature_cols, 'Score': selector.scores_})\n",
    "    scores = scores.sort_values(by='Score', ascending=False)\n",
    "    \n",
    "    print(\"Selected features:\", selected_features)\n",
    "    print(\"\\nFeature scores:\\n\", scores)\n",
    "    \n",
    "    # Save feature scores\n",
    "    scores.to_csv(os.path.join(OUTPUT_PATH, 'feature_scores.csv'), index=False)\n",
    "    \n",
    "    return data, selected_features\n",
    "\n",
    "def dimensionality_reduction(data, selected_features, n_components=3):\n",
    "    \"\"\"Apply PCA for dimensionality reduction (optional).\"\"\"\n",
    "    print(\"\\n--- Dimensionality Reduction (PCA) ---\")\n",
    "    if not selected_features:\n",
    "        print(\"No features selected for PCA.\")\n",
    "        return data\n",
    "    \n",
    "    X = data[selected_features].fillna(0)\n",
    "    \n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=min(n_components, len(selected_features)))\n",
    "    pca_result = pca.fit_transform(X)\n",
    "    \n",
    "    # Add PCA components to data\n",
    "    for i in range(pca_result.shape[1]):\n",
    "        data[f'pca_component_{i+1}'] = pca_result[:, i]\n",
    "    \n",
    "    # Save explained variance\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    print(f\"PCA explained variance ratios: {explained_variance}\")\n",
    "    with open(os.path.join(OUTPUT_PATH, 'pca_results.txt'), 'w') as f:\n",
    "        f.write(f\"Explained Variance Ratios: {explained_variance}\\n\")\n",
    "        f.write(f\"Total Explained Variance: {sum(explained_variance):.4f}\\n\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "def save_data(data):\n",
    "    \"\"\"Save feature-engineered data.\"\"\"\n",
    "    output_file = os.path.join(PREPROCESSED_PATH, 'feature_engineered_data.csv')\n",
    "    data.to_csv(output_file, index=False)\n",
    "    print(f\"Feature-engineered data saved to {output_file}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to execute feature engineering steps.\"\"\"\n",
    "    # Load data\n",
    "    data = load_data()\n",
    "    \n",
    "    # Create new features\n",
    "    data = create_new_features(data)\n",
    "    \n",
    "    # Transform features\n",
    "    data = transform_features(data)\n",
    "    \n",
    "    # Encode categorical features\n",
    "    data = encode_categorical_features(data)\n",
    "    \n",
    "    # Select best features\n",
    "    data, selected_features = select_best_features(data)\n",
    "    \n",
    "    # Dimensionality reduction (optional)\n",
    "    data = dimensionality_reduction(data, selected_features)\n",
    "    \n",
    "    # Save feature-engineered data\n",
    "    save_data(data)\n",
    "    \n",
    "    print(\"Feature engineering completed successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc64a213",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
